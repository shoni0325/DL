{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 Model Class\n",
    "\n",
    "class LeNet(Sequential):\n",
    "    \n",
    "    def __init__(self, input_shape, nb_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='tanh', input_shape=input_shape))\n",
    "        self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "        self.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='tanh'))\n",
    "        self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(120, activation='tanh'))\n",
    "        self.add(Dense(84, activation='tanh'))\n",
    "        self.add(Dense(10, activation='softmax'))\n",
    "        self.compile(optimizer='adam', loss=categorical_crossentropy, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label one_hot_encoding\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train/255.0 , X_test/255.0\n",
    "\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"le_net_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(X_train[0].shape, 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0650 - val_accuracy: 0.9856\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0721 - val_accuracy: 0.9863\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0829 - val_accuracy: 0.9855\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0741 - val_accuracy: 0.9858\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0775 - val_accuracy: 0.9864\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0753 - val_accuracy: 0.9872\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0682 - val_accuracy: 0.9875\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0700 - val_accuracy: 0.9870\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0600 - val_accuracy: 0.9874\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0659 - val_accuracy: 0.9870\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0698 - val_accuracy: 0.9872\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0753 - val_accuracy: 0.9852\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0680 - val_accuracy: 0.9870\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0714 - val_accuracy: 0.9873\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0648 - val_accuracy: 0.9882\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0712 - val_accuracy: 0.9871\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0697 - val_accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0739 - val_accuracy: 0.9860\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0686 - val_accuracy: 0.9877\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0716 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175096ff9d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), verbose=1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8c06c36ee139b972\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8c06c36ee139b972\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
